# Required connection configs for Kafka producer, consumer, and admin
#Add your host here. Alter the port if needed
bootstrap.servers=<bootstrap>:9092
security.protocol=SASL_SSL

# Use the api key and secret created in confluent cloud here as username and password
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<api-key>' password='<api-secret>';
sasl.mechanism=PLAIN

# Required for correctness in Apache Kafka clients prior to 2.6
client.dns.lookup=use_all_dns_ips

# Best practice for higher availability in Apache Kafka clients prior to 3.0
session.timeout.ms=45000

# Best practice for Kafka producer to prevent data loss
acks=all

# Serializers for producer
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer


# Deserializers for consumer
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer


# Required connection configs for Confluent Cloud Schema Registry
# Sample Url => https://psrc.aws.confluent.cloud
schema.registry.url=<sr-endpoint>
basic.auth.credentials.source=USER_INFO
basic.auth.user.info=<sr-api>:<sr-secret>


# group.id=customer-consumer-group-v1
# auto.offset.reset=earliest